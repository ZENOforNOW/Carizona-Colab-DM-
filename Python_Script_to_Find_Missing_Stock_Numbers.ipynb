{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "repeatable_missing_rows_finder.py\n",
        "\n",
        "Output schema (exact order):\n",
        "sale_date, salesrepname, splitsalesrep, manager, bd_agent,\n",
        "f_&_i, f_&_i_2, vehiclestocknumber, first_name, last_name, lead_source\n",
        "\"\"\"\n",
        "\n",
        "import sys, csv\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Iterable, Optional\n",
        "\n",
        "# ===================== USER CONFIG =====================\n",
        "DMS_FILE = \"//content/PaytonListtxt.csv\"                  # e.g., DeskManager / DMS export\n",
        "SHEET_FILE = \"/content/August Google sheet  - Main (14).csv\"  # your Google Sheet export\n",
        "# ======================================================\n",
        "\n",
        "BAD_STOCK_VALUES = {\"\", \"NAN\", \"NONE\", \"NULL\"}\n",
        "\n",
        "OUTPUT_COLUMNS = [\n",
        "    \"sale_date\", \"salesrepname\", \"splitsalesrep\", \"manager\", \"bd_agent\",\n",
        "    \"f_&_i\", \"f_&_i_2\", \"vehiclestocknumber\", \"first_name\", \"last_name\", \"lead_source\"\n",
        "]\n",
        "\n",
        "COLUMN_VARIANTS = {\n",
        "    \"sale_date\":        [\"sale_date\", \"sale date\", \"date\", \"date_of_sale\", \"sold_date\"],\n",
        "    \"salesrepname\":     [\"salesrepname\", \"sales_rep_name\", \"sales_rep\", \"rep\", \"salesperson\"],\n",
        "    \"splitsalesrep\":    [\"splitsalesrep\", \"split_sales_rep\", \"splitrep\", \"split_salesperson\"],\n",
        "    \"manager\":          [\"manager\", \"sales_manager\", \"desk_manager\"],\n",
        "    \"bd_agent\":         [\"bd_agent\", \"bdagent\", \"bd\", \"bd_agent_name\", \"bd rep\"],\n",
        "    \"f_&_i\":            [\"f_&_i\", \"f & i\", \"f_i\", \"finance_manager\", \"fni\", \"f and i\"],\n",
        "    \"f_&_i_2\":          [\"f_&_i_2\", \"f & i 2\", \"f_i_2\", \"finance_manager_2\", \"fni_2\", \"f and i 2\"],\n",
        "    \"vehiclestocknumber\": [\"vehiclestocknumber\", \"vehicle_stock_number\", \"stock_number\", \"stocknumber\", \"stock\", \"stock_no\", \"stocknum\"],\n",
        "    \"first_name\":       [\"first_name\", \"first name\", \"fname\", \"customer_first_name\"],\n",
        "    \"last_name\":        [\"last_name\", \"last name\", \"lname\", \"customer_last_name\", \"surname\"],\n",
        "    \"lead_source\":      [\"lead_source\", \"lead source\", \"source\", \"leadsource\"]\n",
        "}\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def load_norm(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [normalize_header(c) for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def find_first(df: pd.DataFrame, candidates: Iterable[str]) -> Optional[str]:\n",
        "    normalized = [normalize_header(c) for c in candidates]\n",
        "    df_cols = set(df.columns)\n",
        "    for c in normalized:\n",
        "        if c in df_cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def find_stock_col(cols) -> Optional[str]:\n",
        "    candidates = [\n",
        "        \"vehiclestocknumber\", \"stock_number\", \"stocknumber\",\n",
        "        \"vehicle_stock_number\", \"stock\", \"stock_no\", \"stocknum\"\n",
        "    ]\n",
        "    normalized_cols = [normalize_header(c) for c in cols]\n",
        "    for c in candidates:\n",
        "        if c in normalized_cols:\n",
        "            return c\n",
        "    for c in normalized_cols:\n",
        "        if \"stock\" in c:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def clean_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Blank out NaNs/'nan', trim whitespace, normalize newlines, drop quote-only rows.\"\"\"\n",
        "    df = df.copy().where(df.notna(), \"\")\n",
        "    for c in df.columns:\n",
        "        df[c] = (\n",
        "            df[c].astype(str)\n",
        "                 .str.replace(r\"^\\s*nan\\s*$\", \"\", regex=True)\n",
        "                 .str.replace(\"\\r\\n\", \"\\n\")\n",
        "                 .str.replace(\"\\r\", \"\\n\")\n",
        "                 .str.strip()\n",
        "        )\n",
        "    # drop rows that collapse to just a single double-quote\n",
        "    mask_bad = df.apply(lambda r: \"\".join(r.values.astype(str)).strip() == '\"', axis=1)\n",
        "    return df[~mask_bad]\n",
        "\n",
        "def build_output(dms_df: pd.DataFrame, sheet_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    dms_stock = find_stock_col(dms_df.columns)\n",
        "    sheet_stock = find_stock_col(sheet_df.columns)\n",
        "    if dms_stock is None or sheet_stock is None:\n",
        "        raise ValueError(\"Could not find a stock number column in one or both files.\")\n",
        "\n",
        "    dms_df[\"__stock__\"] = dms_df[dms_stock].astype(str).str.upper().str.strip()\n",
        "    sheet_df[\"__stock__\"] = sheet_df[sheet_stock].astype(str).str.upper().str.strip()\n",
        "\n",
        "    dms_df = dms_df[~dms_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "    sheet_df = sheet_df[~sheet_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "\n",
        "    sheet_keys = set(sheet_df[\"__stock__\"])\n",
        "    missing_keys = [s for s in dms_df[\"__stock__\"].tolist() if s not in sheet_keys]\n",
        "    if not missing_keys:\n",
        "        return pd.DataFrame(columns=OUTPUT_COLUMNS)\n",
        "\n",
        "    missing_rows = dms_df[dms_df[\"__stock__\"].isin(missing_keys)].copy()\n",
        "    missing_rows[\"__order__\"] = range(len(missing_rows))\n",
        "\n",
        "    out = pd.DataFrame(index=missing_rows.index, columns=OUTPUT_COLUMNS, dtype=object)\n",
        "    for out_col in OUTPUT_COLUMNS:\n",
        "        if out_col == \"vehiclestocknumber\":\n",
        "            out[out_col] = missing_rows[\"__stock__\"]\n",
        "            continue\n",
        "        src_col = find_first(missing_rows, COLUMN_VARIANTS[out_col])\n",
        "        out[out_col] = missing_rows[src_col] if src_col else \"\"\n",
        "\n",
        "    out[\"__order__\"] = missing_rows[\"__order__\"]\n",
        "    out = out.sort_values(\"__order__\", kind=\"stable\").drop(columns=\"__order__\")\n",
        "\n",
        "    # force strings\n",
        "    for c in OUTPUT_COLUMNS:\n",
        "        out[c] = out[c].astype(str)\n",
        "\n",
        "    return clean_strings(out)\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        dms_df = load_norm(Path(DMS_FILE))\n",
        "        sheet_df = load_norm(Path(SHEET_FILE))\n",
        "        output_df = build_output(dms_df, sheet_df)\n",
        "\n",
        "        # Paste-friendly TSV (optional file)\n",
        "        output_df.to_csv(\"missing_rows.tsv\", sep=\"\\t\", index=False, lineterminator=\"\\n\")\n",
        "\n",
        "        # Clean CSV (fully quoted for Import)\n",
        "        output_df.to_csv(\n",
        "            \"missing_rows.csv\",\n",
        "            index=False,\n",
        "            lineterminator=\"\\n\",\n",
        "            quoting=csv.QUOTE_ALL,\n",
        "            escapechar=\"\\\\\",\n",
        "            na_rep=\"\"\n",
        "        )\n",
        "\n",
        "        # Console preview (CSV, normal-looking)\n",
        "        print(output_df.to_csv(index=False, lineterminator=\"\\n\"))\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Make sure both files are uploaded and paths are correct.\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSn-dgMBUfkc",
        "outputId": "3c905b5e-234e-4562-9f62-54d1fdf59ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sale_date,salesrepname,splitsalesrep,manager,bd_agent,f_&_i,f_&_i_2,vehiclestocknumber,first_name,last_name,lead_source\n",
            "8/20/25,Tim Bateman,,Levi Polege,,Mark Rector,,MP10009,Mark,Sidell,DEALERS WEBSITE\n",
            "8/20/25,Christian Mack,Mark Rector,Suna Faitarouny,,Brent Beck,,MP10049,Noah,Acker,\n",
            "8/20/25,Daniel Lande,,Suna Faitarouny,,Mark Rector,,MP10093,Guadelupe,Alvarado,DEALERS WEBSITE\n",
            "8/20/25,Brandon Beltran,,Mark Rector,,,,MP10218,Wayne,Woodgate,\n",
            "8/20/25,Trey Flores,,Suna Faitarouny,,Brent Beck,,MP10019A,Isaiah,Sanchez,AUTOTRADER\n",
            "8/21/25,,,,,,,MP9442,,,\n",
            "8/21/25,,,,,,,MP10191A,,,\n",
            "8/21/25,Jordan Lecky,,Suna Faitarouny,,Yesenia Felix,,MP10274,Jessyka,Johnson,REPEAT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7NSBLYgIdctj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "missing_stock_numbers_analyzer.py\n",
        "\n",
        "Analyzes two CSV files to find stock numbers present in one but not the other,\n",
        "with an added filter for 'Employee' and 'Whole sale' entries.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from typing import List, Set, Optional, Tuple\n",
        "\n",
        "# --- Helper Functions for Data Loading and Normalization ---\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    \"\"\"Normalizes a column header for consistent access.\"\"\"\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def find_stock_col(cols: List[str]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Tries to find the stock number column from a list of headers.\n",
        "    Returns the normalized column name if found, otherwise None.\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        \"vehiclestocknumber\", \"stock_number\", \"stocknumber\",\n",
        "        \"vehicle_stock_number\", \"stock\", \"stock_no\", \"stocknum\",\n",
        "        \"stock_number\"\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c in cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def load_data(file_path: str) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"Loads a CSV file and normalizes its column headers.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.columns = [normalize_header(c) for c in df.columns]\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "def get_clean_stocks_set(df: pd.DataFrame) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Finds the stock number column in a DataFrame and returns a\n",
        "    set of unique, normalized stock numbers.\n",
        "    \"\"\"\n",
        "    stock_col = find_stock_col(df.columns)\n",
        "    if stock_col is None:\n",
        "        print(f\"Warning: Could not find a stock number column in a dataframe.\")\n",
        "        return set()\n",
        "\n",
        "    # Extract, normalize, and return unique stock numbers\n",
        "    # Filter out junk/empty values\n",
        "    stocks = df[stock_col].astype(str).str.upper().str.strip()\n",
        "    cleaned_stocks = stocks[stocks.str.len() > 0]\n",
        "    return set(cleaned_stocks)\n",
        "\n",
        "# --- Main Analysis Logic ---\n",
        "\n",
        "def analyze_missing_stocks(file1: str, file2: str):\n",
        "    \"\"\"\n",
        "    Compares the stock numbers between two files and prints the results,\n",
        "    with a filter on the first file.\n",
        "    \"\"\"\n",
        "    print(\"--- Analyzing Missing Stock Numbers ---\")\n",
        "    print(f\"File 1 (Filtered): {file1}\")\n",
        "    print(f\"File 2: {file2}\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "    # Load dataframes\n",
        "    df1 = load_data(file1)\n",
        "    df2 = load_data(file2)\n",
        "\n",
        "    if df1 is None or df2 is None:\n",
        "        print(\"Could not load one or both files. Cannot compare.\")\n",
        "        return\n",
        "\n",
        "    # --- ADDED FILTER LOGIC ---\n",
        "    # Filter the first DataFrame to exclude 'employee' and 'whole sale' leads\n",
        "    source_col = 'lead_source'\n",
        "    if source_col in df1.columns:\n",
        "        original_count = len(df1)\n",
        "        df1 = df1[~df1[source_col].astype(str).str.lower().isin(['employee', 'whole sale'])]\n",
        "        filtered_count = len(df1)\n",
        "        print(f\"Filter applied: Removed {original_count - filtered_count} entries from '{file1}'.\")\n",
        "    # --- END ADDED FILTER LOGIC ---\n",
        "\n",
        "    # Get the clean sets of stock numbers\n",
        "    file1_stocks = get_clean_stocks_set(df1)\n",
        "    file2_stocks = get_clean_stocks_set(df2)\n",
        "\n",
        "    if not file1_stocks and not file2_stocks:\n",
        "        print(\"No stock numbers could be extracted from either file. Cannot compare.\")\n",
        "        return\n",
        "\n",
        "    # Find stocks in file1 but not in file2\n",
        "    missing_in_file2 = file1_stocks - file2_stocks\n",
        "\n",
        "    # Find stocks in file2 but not in file1\n",
        "    missing_in_file1 = file2_stocks - file1_stocks\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"\\nStocks in '{file1}' but MISSING from '{file2}':\")\n",
        "    if missing_in_file2:\n",
        "        for stock in sorted(list(missing_in_file2)):\n",
        "            print(f\"- {stock}\")\n",
        "    else:\n",
        "        print(\"None.\")\n",
        "\n",
        "    print(f\"\\nStocks in '{file2}' but MISSING from '{file1}':\")\n",
        "    if missing_in_file1:\n",
        "        for stock in sorted(list(missing_in_file1)):\n",
        "            print(f\"- {stock}\")\n",
        "    else:\n",
        "        print(\"None.\")\n",
        "\n",
        "    print(\"\\n--- Analysis Complete ---\")\n",
        "\n",
        "# --- Entry Point ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    google_sheet_file = \"/content/August Google sheet  - Main (15).csv\"\n",
        "    sales_detail_file = \"/content/SalesDetail_2025-08-21.csv\"\n",
        "    analyze_missing_stocks(google_sheet_file, sales_detail_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRt8LMpz5ZKJ",
        "outputId": "e4f938c1-8ea0-49b8-a3c0-1b2a2861888b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Analyzing Missing Stock Numbers ---\n",
            "File 1 (Filtered): /content/August Google sheet  - Main (15).csv\n",
            "File 2: /content/SalesDetail_2025-08-21.csv\n",
            "-----------------------------------\n",
            "Filter applied: Removed 15 entries from '/content/August Google sheet  - Main (15).csv'.\n",
            "\n",
            "Stocks in '/content/August Google sheet  - Main (15).csv' but MISSING from '/content/SalesDetail_2025-08-21.csv':\n",
            "- MP10049\n",
            "- MP10218\n",
            "- MP9698\n",
            "\n",
            "Stocks in '/content/SalesDetail_2025-08-21.csv' but MISSING from '/content/August Google sheet  - Main (15).csv':\n",
            "None.\n",
            "\n",
            "--- Analysis Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "sales_mismatch_analyzer.py\n",
        "\n",
        "Task:\n",
        "- Compares records between a primary CRM file and a DMS file.\n",
        "- Uses a consistent 'stock_number' field for comparison.\n",
        "- Identifies and reports specific mismatches for both primary and split sales reps.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Set, Optional, Dict, Any\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these two variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the primary CRM sales file (e.g., SalesDetail)\n",
        "CRM_FILE = \"/content/SalesDetail_2025-08-16.csv\"\n",
        "\n",
        "# Name of the DMS file (e.g., PaytonListtxt or a Google Sheet export)\n",
        "DMS_FILE = \"/content/PaytonListtxt.csv\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "BAD_STOCK_VALUES = {\"\", \"NAN\", \"NONE\", \"NULL\"}\n",
        "STOCK_COL_NAME = \"stock_number\"\n",
        "SALESREP_COL_NAME = \"salesrepname\"\n",
        "SPLITSALESREP_COL_NAME = \"splitsalesrep\"\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    \"\"\"Normalizes a column header for consistent access.\"\"\"\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def find_and_standardize_cols(df: pd.DataFrame, original_col_names: List[str], target_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Finds a column from a list of candidates and renames it to a standard name.\n",
        "    \"\"\"\n",
        "    normalized_cols = [normalize_header(c) for c in df.columns]\n",
        "\n",
        "    found_col_norm = None\n",
        "    for c in original_col_names:\n",
        "        if c in normalized_cols:\n",
        "            found_col_norm = c\n",
        "            break\n",
        "\n",
        "    if found_col_norm:\n",
        "        original_col_name = df.columns[normalized_cols.index(found_col_norm)]\n",
        "        if original_col_name != target_name:\n",
        "            df = df.rename(columns={original_col_name: target_name})\n",
        "        return df\n",
        "    else:\n",
        "        # If column not found, add a blank column to avoid KeyError later\n",
        "        df[target_name] = \"MISSING\"\n",
        "        return df\n",
        "\n",
        "def load_clean(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads a CSV, cleans headers, and standardizes column names for analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        # Normalize all column names first\n",
        "        df.columns = [normalize_header(c) for c in df.columns]\n",
        "\n",
        "        # Standardize key columns\n",
        "        df = find_and_standardize_cols(df, [\"stock_number\", \"vehiclestocknumber\", \"stock\"], STOCK_COL_NAME)\n",
        "        df = find_and_standardize_cols(df, [\"sales_rep\", \"salesrepname\"], SALESREP_COL_NAME)\n",
        "        df = find_and_standardize_cols(df, [\"split_sales_rep\", \"splitsalesrep\"], SPLITSALESREP_COL_NAME)\n",
        "\n",
        "        # Clean the stock number data\n",
        "        df[STOCK_COL_NAME] = df[STOCK_COL_NAME].astype(str).str.upper().str.strip()\n",
        "        return df.fillna(\"MISSING\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{path}' was not found.\", file=sys.stderr)\n",
        "        raise\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}. One of the files may be missing a required column.\", file=sys.stderr)\n",
        "        raise\n",
        "\n",
        "# Drop duplicates\n",
        "def drop_duplicates_and_set_index(df: pd.DataFrame, subset_col: str) -> Dict[str, Any]:\n",
        "    df = df.drop_duplicates(subset=subset_col, keep=\"first\")\n",
        "    return df.set_index(subset_col).to_dict(\"index\")\n",
        "\n",
        "def analyze_mismatches(crm_dict: Dict[str, Any], dms_dict: Dict[str, Any]):\n",
        "    mismatches = []\n",
        "\n",
        "    for stock, crm_row in crm_dict.items():\n",
        "        dms_row = dms_dict.get(stock)\n",
        "\n",
        "        if dms_row is None:\n",
        "            continue\n",
        "\n",
        "        # Get specific values for each field\n",
        "        crm_salesrep = str(crm_row.get(SALESREP_COL_NAME, \"MISSING\")).strip().lower()\n",
        "        dms_salesrep = str(dms_row.get(SALESREP_COL_NAME, \"MISSING\")).strip().lower()\n",
        "\n",
        "        crm_splitsalesrep = str(crm_row.get(SPLITSALESREP_COL_NAME, \"MISSING\")).strip().lower()\n",
        "        dms_splitsalesrep = str(dms_row.get(SPLITSALESREP_COL_NAME, \"MISSING\")).strip().lower()\n",
        "\n",
        "        # New logic: Check if the *set* of names is different.\n",
        "        crm_reps_set = {crm_salesrep, crm_splitsalesrep} - {\"missing\", \"\"}\n",
        "        dms_reps_set = {dms_salesrep, dms_splitsalesrep} - {\"missing\", \"\"}\n",
        "\n",
        "        if crm_reps_set != dms_reps_set:\n",
        "            mismatches.append({\n",
        "                \"stock_number\": stock,\n",
        "                \"Field\": \"Sales Reps\",\n",
        "                \"Salesrep value in CRM\": crm_salesrep,\n",
        "                \"Salesrep value in DMS\": dms_salesrep,\n",
        "                \"SplitSalesrep value in CRM\": crm_splitsalesrep,\n",
        "                \"SplitSalesrep value in DMS\": dms_splitsalesrep,\n",
        "            })\n",
        "\n",
        "    mismatch_df = pd.DataFrame(mismatches)\n",
        "    print(\"\\n--- Sales Rep Mismatch Report ---\")\n",
        "    if not mismatch_df.empty:\n",
        "        print(mismatch_df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"No mismatches found between the CRM and DMS files.\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Load and clean both files\n",
        "        crm_df = load_clean(CRM_FILE)\n",
        "        dms_df = load_clean(DMS_FILE)\n",
        "\n",
        "        # Convert to dictionaries for efficient lookup\n",
        "        crm_dict = drop_duplicates_and_set_index(crm_df, STOCK_COL_NAME)\n",
        "        dms_dict = drop_duplicates_and_set_index(dms_df, STOCK_COL_NAME)\n",
        "\n",
        "        # Run the analysis\n",
        "        analyze_mismatches(crm_dict, dms_dict)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"ERROR: {e}. Please ensure the input files are uploaded to Colab.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"ERROR: {e}. One of the files may be missing a required column.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95_SltuzfLMG",
        "outputId": "faf907dc-cf4d-457a-9d93-f7e8af2f5bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sales Rep Mismatch Report ---\n",
            "stock_number      Field Salesrep value in CRM Salesrep value in DMS SplitSalesrep value in CRM SplitSalesrep value in DMS\n",
            "      MP9807 Sales Reps           trey flores         robert emmons              robert emmons                    missing\n",
            "      MP8991 Sales Reps         jesus galindo          will deguire                    missing              robert emmons\n",
            "     MP10234 Sales Reps           tim bateman           tim bateman            brandon beltran                    missing\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "lead_source_mismatch_analyzer.py\n",
        "\n",
        "Task:\n",
        "- Compares the 'lead_source' field across three CSV files:\n",
        "  - a primary sales detail log\n",
        "  - a Google Sheet export\n",
        "  - a PaytonList DMS export\n",
        "- Standardizes similar lead sources (e.g., 'Facebook Marketplace' -> 'Facebook')\n",
        "  to avoid false mismatches.\n",
        "- Identifies and reports any records where the standardized 'lead_source' value\n",
        "  does not match across all three files.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these three variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the primary sales file (e.g., SalesDetail)\n",
        "SALES_FILE = \"/content/SalesDetail_2025-08-16.csv\"\n",
        "\n",
        "# Name of the Google Sheet file\n",
        "GOOGLE_SHEET_FILE = \"/content/August Google sheet  - Main (11).csv\"\n",
        "\n",
        "# Name of the PaytonList DMS file\n",
        "PAYTON_LIST_FILE = \"/content/PaytonListtxt.csv\"\n",
        "\n",
        "# Lead source keywords to standardize.\n",
        "# The key is the standardized root name, and the list contains keywords to match.\n",
        "SOURCE_MAPPING = {\n",
        "    \"cargurus\": [\"cargurus\", \"cargurus - digital deal\", \"cargurus - credit app\", \"cargurus - soft pull\"],\n",
        "    \"facebook\": [\"facebook\", \"facebook market place\", \"facebook marketplace\"],\n",
        "    \"autotrader\": [\"autotrader\", \"autotrader.com\", \"autotrader group\"],\n",
        "    \"cars.com\": [\"cars.com\", \"cars.com was source\"],\n",
        "    \"dealers website\": [\"dealer website\", \"dealers website\", \"dealers website\", \"vin\", \"vinsolutions - finance application\"],\n",
        "    \"carfax\": [\"carfax\", \"carfax, inc\"],\n",
        "    \"truecar\": [\"truecar\", \"truecar group\"],\n",
        "    \"repeat\": [\"repeat\", \"referral\", \"referral/repeat\"],\n",
        "    \"walk-in\": [\"walk-in\"],\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Candidate columns for stock number\n",
        "POSSIBLE_STOCK_COLS = [\n",
        "    \"vehiclestocknumber\", \"stock_number\", \"stock\"\n",
        "]\n",
        "\n",
        "# Strings to treat as empty\n",
        "BAD_SENTINELS = {\"\", \"nan\", \"none\", \"null\", \"na\", \"n/a\", \"missing\"}\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    \"\"\"Normalizes a column header for consistent access.\"\"\"\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Finds a column name in a DataFrame from a list of candidates.\"\"\"\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def standardize_source(source: str) -> str:\n",
        "    \"\"\"Standardizes a lead source string based on a predefined mapping.\"\"\"\n",
        "    source = str(source).strip().lower()\n",
        "    for root, keywords in SOURCE_MAPPING.items():\n",
        "        if any(keyword in source for keyword in keywords):\n",
        "            return root\n",
        "    return source  # Return original if no match found\n",
        "\n",
        "def load_and_clean(path: str) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"\n",
        "    Loads a CSV file, standardizes column names, and cleans key fields.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        # Standardize headers to lowercase with underscores\n",
        "        df.columns = df.columns.str.lower().str.strip().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
        "\n",
        "        # Find and standardize the stock number column\n",
        "        stock_col = find_column(df, POSSIBLE_STOCK_COLS)\n",
        "        if stock_col is None:\n",
        "             raise KeyError(\"Could not find a stock number column in the file.\")\n",
        "\n",
        "        df[stock_col] = df[stock_col].astype(str).str.upper().str.strip()\n",
        "\n",
        "        # Clean and standardize the lead source column\n",
        "        lead_source_col = find_column(df, [\"lead_source\", \"lead_source_group\"])\n",
        "        if lead_source_col is None:\n",
        "            df[\"lead_source\"] = \"MISSING\"\n",
        "        else:\n",
        "            df[\"lead_source\"] = df[lead_source_col].fillna(\"MISSING\").apply(standardize_source)\n",
        "\n",
        "        return df, stock_col\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{path}' was not found.\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: A required column was not found in '{path}': {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "def drop_duplicates_and_set_index(df: pd.DataFrame, subset_col: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Drops duplicate rows and converts a DataFrame to a dictionary for lookup.\n",
        "    \"\"\"\n",
        "    df = df.drop_duplicates(subset=subset_col, keep=\"first\")\n",
        "    return df.set_index(subset_col).to_dict(\"index\")\n",
        "\n",
        "def analyze_lead_source_mismatches():\n",
        "    \"\"\"\n",
        "    Main function to load files, compare lead sources, and report mismatches.\n",
        "    \"\"\"\n",
        "    # Load and clean all three data files\n",
        "    sales_df, sales_stock_col = load_and_clean(SALES_FILE)\n",
        "    google_df, google_stock_col = load_and_clean(GOOGLE_SHEET_FILE)\n",
        "    payton_df, payton_stock_col = load_and_clean(PAYTON_LIST_FILE)\n",
        "\n",
        "    # Convert to lookup dictionaries\n",
        "    sales_dict = drop_duplicates_and_set_index(sales_df, sales_stock_col)\n",
        "    google_dict = drop_duplicates_and_set_index(google_df, google_stock_col)\n",
        "    payton_dict = drop_duplicates_and_set_index(payton_df, payton_stock_col)\n",
        "\n",
        "    mismatches = []\n",
        "\n",
        "    # Iterate through the sales data to check for discrepancies\n",
        "    for stock, sales_row in sales_dict.items():\n",
        "        source_sold = sales_row.get(\"lead_source\", \"MISSING\")\n",
        "        google_row = google_dict.get(stock)\n",
        "        payton_row = payton_dict.get(stock)\n",
        "\n",
        "        if not google_row or not payton_row:\n",
        "            continue\n",
        "\n",
        "        source_google = google_row.get(\"lead_source\", \"MISSING\")\n",
        "        source_payton = payton_row.get(\"lead_source\", \"MISSING\")\n",
        "\n",
        "        if (source_sold != source_google) or (source_sold != source_payton):\n",
        "            mismatches.append({\n",
        "                \"vehiclestocknumber\": stock,\n",
        "                \"field\": \"lead_source\",\n",
        "                \"SalesDetail\": source_sold,\n",
        "                \"GoogleSheet\": source_google,\n",
        "                \"PaytonList\": source_payton\n",
        "            })\n",
        "\n",
        "    mismatch_df = pd.DataFrame(mismatches)\n",
        "\n",
        "    print(\"\\n--- Lead Source Mismatch Report ---\")\n",
        "    if not mismatch_df.empty:\n",
        "        print(mismatch_df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"No lead source mismatches found across the three files.\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_lead_source_mismatches()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVF8P_kGlQ4x",
        "outputId": "1d36adde-e8d0-4c45-fb50-683ab8979b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Lead Source Mismatch Report ---\n",
            "vehiclestocknumber       field          SalesDetail GoogleSheet PaytonList\n",
            "            MP9655 lead_source              truecar    true car   true car\n",
            "           MP10040 lead_source          auto fusion  autofusion autofusion\n",
            "           MP10128 lead_source               carfax     missing     carfax\n",
            "           MP10197 lead_source      dealers website    cargurus   cargurus\n",
            "            MP9790 lead_source engage to sell sales      engage     engage\n",
            "            MP9980 lead_source              truecar    true car   true car\n",
            "           MP10193 lead_source      dealers website      repeat     repeat\n",
            "            MP9983 lead_source             cargurus     walk-in    walk-in\n",
            "           MP10065 lead_source             cargurus    employee   cargurus\n",
            "           MP10121 lead_source             facebook     missing    missing\n",
            "           MP8793A lead_source          auto fusion    cargurus   cargurus\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "manager_mismatch_analyzer.py\n",
        "\n",
        "Task:\n",
        "- Compares records between a primary CRM file and a DMS file.\n",
        "- Identifies and reports mismatches in manager and BD agent names.\n",
        "- Uses a consistent 'vehiclestocknumber' field for comparison.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Set, Optional, Dict, Any\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these two variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the primary CRM file (e.g., SalesDetail)\n",
        "CRM_FILE = \"/content/SalesDetail_2025-08-13 (4).csv\"\n",
        "\n",
        "# Name of the DMS file (e.g., PaytonListtxt or a Google Sheet export)\n",
        "DMS_FILE = \"/content/August Google sheet  - Main (6).csv\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "BAD_STOCK_VALUES = {\"\", \"NAN\", \"NONE\", \"NULL\"}\n",
        "STOCK_COL_NAME = \"vehiclestocknumber\"\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    \"\"\"Normalizes a column header for consistent access.\"\"\"\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def find_and_standardize_cols(df: pd.DataFrame, candidates: List[str], target_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Finds a column from a list of candidates and renames it to a standard name.\n",
        "    \"\"\"\n",
        "    normalized_cols = [normalize_header(c) for c in df.columns]\n",
        "\n",
        "    found_col_norm = None\n",
        "    for c in candidates:\n",
        "        if c in normalized_cols:\n",
        "            found_col_norm = c\n",
        "            break\n",
        "\n",
        "    if found_col_norm:\n",
        "        original_col_name = df.columns[normalized_cols.index(found_col_norm)]\n",
        "        if original_col_name != target_name:\n",
        "            df = df.rename(columns={original_col_name: target_name})\n",
        "        return df\n",
        "    else:\n",
        "        raise KeyError(f\"Could not find a required column. Tried candidates: {candidates}\")\n",
        "\n",
        "def load_and_clean(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads a CSV file, standardizes column names, and cleans key fields.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        # Standardize headers to lowercase with underscores\n",
        "        df.columns = df.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
        "\n",
        "        # Standardize the stock number column name\n",
        "        df = find_and_standardize_cols(df, [\"vehiclestocknumber\", \"stock_number\", \"stock\"], STOCK_COL_NAME)\n",
        "\n",
        "        # Standardize manager and BD agent column names\n",
        "        df = find_and_standardize_cols(df, [\"manager\", \"manager_name\"], \"manager\")\n",
        "        df = find_and_standardize_cols(df, [\"bd_agent\"], \"bd_agent\")\n",
        "\n",
        "        # Clean up the stock number and manager columns\n",
        "        df[STOCK_COL_NAME] = df[STOCK_COL_NAME].astype(str).str.upper().str.strip()\n",
        "        df = df.fillna(\"MISSING\")\n",
        "\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{path}' was not found.\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: A required column was not found in '{path}': {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "def normalize_people(row: Dict[str, Any], cols: List[str]) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extracts and normalizes names from specified columns into a set.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        str(row.get(col, \"MISSING\")).strip().lower()\n",
        "        for col in cols if str(row.get(col, \"MISSING\")).strip().lower() not in [\"missing\", \"\"]\n",
        "    }\n",
        "\n",
        "def drop_duplicates_and_set_index(df: pd.DataFrame, subset_col: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Drops duplicate rows and converts a DataFrame to a dictionary for lookup.\n",
        "    \"\"\"\n",
        "    df = df.drop_duplicates(subset=subset_col, keep=\"first\")\n",
        "    return df.set_index(subset_col).to_dict(\"index\")\n",
        "\n",
        "def analyze_manager_mismatches():\n",
        "    \"\"\"\n",
        "    Main function to load files, compare manager/BD agent, and report mismatches.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and clean both data files\n",
        "        crm_df = load_and_clean(CRM_FILE)\n",
        "        dms_df = load_and_clean(DMS_FILE)\n",
        "\n",
        "        # Convert the DMS dataframe to a lookup dictionary\n",
        "        dms_dict = drop_duplicates_and_set_index(dms_df, STOCK_COL_NAME)\n",
        "\n",
        "        mismatches = []\n",
        "\n",
        "        for _, crm_row in crm_df.iterrows():\n",
        "            stock = crm_row[STOCK_COL_NAME]\n",
        "            dms_row = dms_dict.get(stock)\n",
        "\n",
        "            # Skip if the record isn't in both files\n",
        "            if dms_row is None:\n",
        "                continue\n",
        "\n",
        "            # Extract and normalize manager/BD agent names from both sources\n",
        "            crm_managers = normalize_people(crm_row, [\"manager\", \"bd_agent\"])\n",
        "            dms_managers = normalize_people(dms_row, [\"manager\", \"bd_agent\"])\n",
        "\n",
        "            # Compare the sets of names\n",
        "            if crm_managers != dms_managers:\n",
        "                mismatches.append({\n",
        "                    \"stock_number\": stock,\n",
        "                    \"field\": \"Managers\",\n",
        "                    \"value_in_crm\": sorted(list(crm_managers)) or [\"MISSING\"],\n",
        "                    \"value_in_dms\": sorted(list(dms_managers)) or [\"MISSING\"],\n",
        "                })\n",
        "\n",
        "        mismatch_df = pd.DataFrame(mismatches)\n",
        "\n",
        "        print(\"\\n--- Manager Mismatch Report ---\")\n",
        "        if not mismatch_df.empty:\n",
        "            print(mismatch_df.to_string(index=False))\n",
        "        else:\n",
        "            print(\"No manager mismatches found between the CRM and DMS files.\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_manager_mismatches()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Iw7ARvAkLN",
        "outputId": "fffc940b-1cee-4494-d383-f67960a8d4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Manager Mismatch Report ---\n",
            "stock_number    field  value_in_crm     value_in_dms\n",
            "     MP10150 Managers [levi polege] [jamie sheridan]\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "attribute_sales_compare.py\n",
        "\n",
        "Task:\n",
        "- Loads two CSVs (CRM and DMS), cleans columns, computes sales attribution\n",
        "  per person using simple rules, and outputs a side-by-side comparison.\n",
        "\n",
        "Attribution rules:\n",
        "- Full sale (1.0): exactly one of {manager, bd_agent} is present.\n",
        "- Split sale (0.5 each): both present.\n",
        "- Unassigned (1.0): neither present -> credited to \"unassigned\".\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the CRM file\n",
        "CRM_FILE = \"/content/August Google sheet  - Main (8).csv\"\n",
        "\n",
        "# Name of the DMS file\n",
        "DMS_FILE = \"/content/SalesDetail_2025-08-13 (6).csv\"\n",
        "\n",
        "# Directory to save the output files\n",
        "OUT_DIR = \"out\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Candidate columns\n",
        "POSSIBLE_MANAGER_COLS = [\n",
        "    \"manager\", \"sales_manager\", \"salesmanager\", \"desk_manager\", \"deskmanager\"\n",
        "]\n",
        "POSSIBLE_BD_COLS = [\n",
        "    \"bd_agent\", \"bdagent\", \"business_development\", \"bd\", \"internet_agent\", \"internet_manager\"\n",
        "]\n",
        "\n",
        "# Strings to treat as empty\n",
        "BAD_SENTINELS = {\"\", \"nan\", \"none\", \"null\", \"na\", \"n/a\", \"missing\"}\n",
        "\n",
        "def normalize_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Normalizes DataFrame headers for consistent access.\"\"\"\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "        .str.replace(\"-\", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Finds a column name in a DataFrame from a list of candidates.\"\"\"\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def cleaned_series(s: Optional[pd.Series]) -> pd.Series:\n",
        "    \"\"\"Cleans a Series of strings for consistent processing.\"\"\"\n",
        "    if s is None:\n",
        "        return pd.Series([], dtype=str)\n",
        "    s = s.fillna(\"\")\n",
        "    s = s.astype(str).str.strip().str.lower()\n",
        "    s = s.apply(lambda x: \"\" if x in BAD_SENTINELS else x)\n",
        "    return s\n",
        "\n",
        "def load_and_prepare(path: Path) -> Tuple[pd.DataFrame, str, str]:\n",
        "    \"\"\"Loads a CSV, cleans headers, and identifies manager/BD agent columns.\"\"\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df = normalize_headers(df)\n",
        "\n",
        "    manager_col = find_column(df, POSSIBLE_MANAGER_COLS)\n",
        "    bd_col = find_column(df, POSSIBLE_BD_COLS)\n",
        "\n",
        "    # If missing, create empty columns to keep logic simple\n",
        "    if manager_col is None:\n",
        "        manager_col = \"__manager_missing__\"\n",
        "        df[manager_col] = \"\"\n",
        "    if bd_col is None:\n",
        "        bd_col = \"__bd_missing__\"\n",
        "        df[bd_col] = \"\"\n",
        "\n",
        "    df[manager_col] = cleaned_series(df[manager_col])\n",
        "    df[bd_col] = cleaned_series(df[bd_col])\n",
        "\n",
        "    return df, manager_col, bd_col\n",
        "\n",
        "def tally_attribution(df: pd.DataFrame, manager_col: str, bd_col: str) -> Dict[str, float]:\n",
        "    \"\"\"Counts attributed sales based on defined rules.\"\"\"\n",
        "    counts: defaultdict[str, float] = defaultdict(float)\n",
        "    for m, b in zip(df[manager_col], df[bd_col]):\n",
        "        has_m = bool(m)\n",
        "        has_b = bool(b)\n",
        "        if has_m and not has_b:\n",
        "            counts[m] += 1.0\n",
        "        elif has_b and not has_m:\n",
        "            counts[b] += 1.0\n",
        "        elif has_m and has_b:\n",
        "            counts[m] += 0.5\n",
        "            counts[b] += 0.5\n",
        "        else:\n",
        "            counts[\"unassigned\"] += 1.0\n",
        "    return dict(counts)\n",
        "\n",
        "def dict_to_df(d: Dict[str, float], count_label: str) -> pd.DataFrame:\n",
        "    \"\"\"Converts a dictionary of counts into a sorted DataFrame.\"\"\"\n",
        "    return (\n",
        "        pd.DataFrame(list(d.items()), columns=[\"person\", count_label])\n",
        "        .sort_values(by=count_label, ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "def compare_side_by_side(crm_df: pd.DataFrame, dms_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Merges CRM and DMS data to show a side-by-side comparison.\"\"\"\n",
        "    merged = pd.merge(crm_df, dms_df, on=\"person\", how=\"outer\").fillna(0.0)\n",
        "    merged[\"diff_dms_minus_crm\"] = merged[\"dms_count\"] - merged[\"crm_count\"]\n",
        "    merged = merged.sort_values(by=[\"diff_dms_minus_crm\", \"person\"], ascending=[False, True]).reset_index(drop=True)\n",
        "    return merged\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        crm_path = Path(CRM_FILE)\n",
        "        dms_path = Path(DMS_FILE)\n",
        "        outdir = Path(OUT_DIR)\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Load + tally CRM\n",
        "        crm_df, mcol_crm, bcol_crm = load_and_prepare(crm_path)\n",
        "        crm_counts = tally_attribution(crm_df, mcol_crm, bcol_crm)\n",
        "        crm_tbl = dict_to_df(crm_counts, \"crm_count\")\n",
        "\n",
        "        # Load + tally DMS\n",
        "        dms_df, mcol_dms, bcol_dms = load_and_prepare(dms_path)\n",
        "        dms_counts = tally_attribution(dms_df, mcol_dms, bcol_dms)\n",
        "        dms_tbl = dict_to_df(dms_counts, \"dms_count\")\n",
        "\n",
        "        # Compare\n",
        "        comparison = compare_side_by_side(crm_tbl, dms_tbl)\n",
        "\n",
        "        # Define output file paths\n",
        "        crm_out = outdir / \"crm_attribution.csv\"\n",
        "        dms_out = outdir / \"dms_attribution.csv\"\n",
        "        comp_out = outdir / \"comparison_side_by_side.csv\"\n",
        "\n",
        "        # Save output files\n",
        "        crm_tbl.to_csv(crm_out, index=False)\n",
        "        dms_tbl.to_csv(dms_out, index=False)\n",
        "        comparison.to_csv(comp_out, index=False)\n",
        "\n",
        "        # Console summary\n",
        "        print(\"\\n=== CRM Attribution (top 10) ===\")\n",
        "        print(crm_tbl.head(10).to_string(index=False))\n",
        "        print(\"\\n=== DMS Attribution (top 10) ===\")\n",
        "        print(dms_tbl.head(10).to_string(index=False))\n",
        "        print(\"\\n=== Side-by-Side Comparison (top 20 by diff) ===\")\n",
        "        print(comparison.head(20).to_string(index=False))\n",
        "        print(f\"\\nColumns used -> CRM: manager='{mcol_crm}', bd_agent='{bcol_crm}' | DMS: manager='{mcol_dms}', bd_agent='{bcol_dms}'\")\n",
        "        print(f\"Wrote files:\\n- {crm_out}\\n- {dms_out}\\n- {comp_out}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Please ensure the input files are uploaded and the names match the configuration.\", file=sys.stderr)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: A required column was not found in one of the files: {e}\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzss5tWef51H",
        "outputId": "b650501b-a431-4d99-95b8-56c3b17f620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CRM Attribution (top 10) ===\n",
            "         person  crm_count\n",
            "suna faitarouny       48.0\n",
            " jamie sheridan       13.5\n",
            "    levi polege       12.5\n",
            "     unassigned        5.0\n",
            "\n",
            "=== DMS Attribution (top 10) ===\n",
            "         person  dms_count\n",
            "suna faitarouny       46.0\n",
            " jamie sheridan       13.5\n",
            "    levi polege       12.5\n",
            "\n",
            "=== Side-by-Side Comparison (top 20 by diff) ===\n",
            "         person  crm_count  dms_count  diff_dms_minus_crm\n",
            " jamie sheridan       13.5       13.5                 0.0\n",
            "    levi polege       12.5       12.5                 0.0\n",
            "suna faitarouny       48.0       46.0                -2.0\n",
            "     unassigned        5.0        0.0                -5.0\n",
            "\n",
            "Columns used -> CRM: manager='manager', bd_agent='bd_agent' | DMS: manager='manager', bd_agent='bd_agent'\n",
            "Wrote files:\n",
            "- out/crm_attribution.csv\n",
            "- out/dms_attribution.csv\n",
            "- out/comparison_side_by_side.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "mismatch_stock_finder.py\n",
        "\n",
        "Task:\n",
        "- Compares sales attribution between a CRM file and a DMS file.\n",
        "- Identifies and reports specific stock numbers where manager/BD agent\n",
        "  attribution differs between the two files.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional, Set, Tuple\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the CRM file\n",
        "CRM_FILE = \"/content/SalesDetail_2025-08-13 (6).csv\"\n",
        "\n",
        "# Name of the DMS file\n",
        "DMS_FILE = \"/content/August Google sheet  - Main (8).csv\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Candidate columns\n",
        "POSSIBLE_MANAGER_COLS = [\n",
        "    \"manager\", \"sales_manager\", \"salesmanager\", \"desk_manager\", \"deskmanager\"\n",
        "]\n",
        "POSSIBLE_BD_COLS = [\n",
        "    \"bd_agent\", \"bdagent\", \"business_development\", \"bd\", \"internet_agent\", \"internet_manager\"\n",
        "]\n",
        "\n",
        "# Strings to treat as empty\n",
        "BAD_SENTINELS = {\"\", \"nan\", \"none\", \"null\", \"na\", \"n/a\", \"missing\"}\n",
        "\n",
        "def normalize_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Normalizes DataFrame headers for consistent access.\"\"\"\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "        .str.replace(\"-\", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Finds a column name in a DataFrame from a list of candidates.\"\"\"\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def cleaned_series(s: Optional[pd.Series]) -> pd.Series:\n",
        "    \"\"\"Cleans a Series of strings for consistent processing.\"\"\"\n",
        "    if s is None:\n",
        "        return pd.Series([], dtype=str)\n",
        "    s = s.fillna(\"\")\n",
        "    s = s.astype(str).str.strip().str.lower()\n",
        "    s = s.apply(lambda x: \"\" if x in BAD_SENTINELS else x)\n",
        "    return s\n",
        "\n",
        "def load_and_prepare(path: Path) -> Tuple[pd.DataFrame, str, str, str]:\n",
        "    \"\"\"\n",
        "    Loads a CSV, cleans headers, and identifies key columns.\n",
        "    Returns the DataFrame and the identified column names.\n",
        "    \"\"\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df = normalize_headers(df)\n",
        "\n",
        "    stock_col = find_column(df, [\"vehiclestocknumber\", \"stock_number\", \"stock\"])\n",
        "    manager_col = find_column(df, POSSIBLE_MANAGER_COLS)\n",
        "    bd_col = find_column(df, POSSIBLE_BD_COLS)\n",
        "\n",
        "    if stock_col is None:\n",
        "        raise KeyError(f\"Could not find a stock number column in file: {path}\")\n",
        "\n",
        "    # If missing, create empty columns to keep logic simple\n",
        "    if manager_col is None:\n",
        "        manager_col = \"__manager_missing__\"\n",
        "        df[manager_col] = \"\"\n",
        "    if bd_col is None:\n",
        "        bd_col = \"__bd_missing__\"\n",
        "        df[bd_col] = \"\"\n",
        "\n",
        "    df[stock_col] = cleaned_series(df[stock_col])\n",
        "    df[manager_col] = cleaned_series(df[manager_col])\n",
        "    df[bd_col] = cleaned_series(df[bd_col])\n",
        "\n",
        "    return df, stock_col, manager_col, bd_col\n",
        "\n",
        "def get_attribution_set(row: Dict[str, Any], manager_col: str, bd_col: str) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extracts and cleans manager/BD agent names from a row into a set.\n",
        "    \"\"\"\n",
        "    names = {row[manager_col], row[bd_col]}\n",
        "    return {name for name in names if name and name not in BAD_SENTINELS}\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        crm_path = Path(CRM_FILE)\n",
        "        dms_path = Path(DMS_FILE)\n",
        "\n",
        "        # Load + prep both files\n",
        "        crm_df, crm_stock, crm_mgr_col, crm_bd_col = load_and_prepare(crm_path)\n",
        "        dms_df, dms_stock, dms_mgr_col, dms_bd_col = load_and_prepare(dms_path)\n",
        "\n",
        "        # Create lookup dictionaries for efficient comparison\n",
        "        crm_dict = crm_df.drop_duplicates(subset=crm_stock).set_index(crm_stock).T.to_dict('dict')\n",
        "        dms_dict = dms_df.drop_duplicates(subset=dms_stock).set_index(dms_stock).T.to_dict('dict')\n",
        "\n",
        "        mismatches = []\n",
        "\n",
        "        # Iterate over all stock numbers found in the CRM file\n",
        "        for stock_num, crm_row in crm_dict.items():\n",
        "            if stock_num in dms_dict:\n",
        "                dms_row = dms_dict[stock_num]\n",
        "\n",
        "                crm_reps = get_attribution_set(crm_row, crm_mgr_col, crm_bd_col)\n",
        "                dms_reps = get_attribution_set(dms_row, dms_mgr_col, dms_bd_col)\n",
        "\n",
        "                # Check for a mismatch in the combined set of attributed reps\n",
        "                if crm_reps != dms_reps:\n",
        "                    mismatches.append({\n",
        "                        \"stock_number\": stock_num,\n",
        "                        \"crm_attribution\": sorted(list(crm_reps)) if crm_reps else \"unassigned\",\n",
        "                        \"dms_attribution\": sorted(list(dms_reps)) if dms_reps else \"unassigned\",\n",
        "                    })\n",
        "\n",
        "        mismatch_df = pd.DataFrame(mismatches)\n",
        "\n",
        "        print(\"\\n=== Manager/BD Agent Mismatches by Stock Number ===\")\n",
        "        if not mismatch_df.empty:\n",
        "            # Format the list of reps for better readability\n",
        "            mismatch_df['crm_attribution'] = mismatch_df['crm_attribution'].apply(lambda x: \", \".join(x).title() if isinstance(x, list) else x.title())\n",
        "            mismatch_df['dms_attribution'] = mismatch_df['dms_attribution'].apply(lambda x: \", \".join(x).title() if isinstance(x, list) else x.title())\n",
        "            print(mismatch_df.to_string(index=False))\n",
        "        else:\n",
        "            print(\"No discrepancies found between CRM and DMS attribution.\")\n",
        "        print(\"-----------------------------------------------------\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Please ensure the input files are uploaded and the names match the configuration.\", file=sys.stderr)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: A required column was not found in one of the files: {e}\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn09XWAhqiVj",
        "outputId": "a4c0a5ea-3830-4009-d007-5c542f5cb005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Manager/BD Agent Mismatches by Stock Number ===\n",
            "No discrepancies found between CRM and DMS attribution.\n",
            "-----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "single_manager_audit_tool.py\n",
        "\n",
        "Task:\n",
        "- Audits a specific manager's sales attribution between a CRM and a DMS file.\n",
        "- Identifies and reports stock numbers where the manager's attribution is either\n",
        "  missing or misattributed between the two files.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional, Set, Tuple\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these variables to point to your input files and the manager to audit.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the CRM file\n",
        "CRM_FILE = \"/content/SalesDetail_2025-08-13 (6).csv\"\n",
        "\n",
        "# Name of the DMS file\n",
        "DMS_FILE = \"/content/August Google sheet  - Main (8).csv\"\n",
        "\n",
        "# The name of the manager to audit (case-insensitive)\n",
        "TARGET_MANAGER = \"suna faitarouny\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Candidate columns\n",
        "POSSIBLE_MANAGER_COLS = [\n",
        "    \"manager\", \"sales_manager\", \"salesmanager\", \"desk_manager\", \"deskmanager\"\n",
        "]\n",
        "POSSIBLE_BD_COLS = [\n",
        "    \"bd_agent\", \"bdagent\", \"business_development\", \"bd\", \"internet_agent\", \"internet_manager\"\n",
        "]\n",
        "\n",
        "# Strings to treat as empty\n",
        "BAD_SENTINELS = {\"\", \"nan\", \"none\", \"null\", \"na\", \"n/a\", \"missing\"}\n",
        "\n",
        "def normalize_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Normalizes DataFrame headers for consistent access.\"\"\"\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "        .str.replace(\"-\", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Finds a column name in a DataFrame from a list of candidates.\"\"\"\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def cleaned_series(s: Optional[pd.Series]) -> pd.Series:\n",
        "    \"\"\"Cleans a Series of strings for consistent processing.\"\"\"\n",
        "    if s is None:\n",
        "        return pd.Series([], dtype=str)\n",
        "    s = s.fillna(\"\")\n",
        "    s = s.astype(str).str.strip().str.lower()\n",
        "    s = s.apply(lambda x: \"\" if x in BAD_SENTINELS else x)\n",
        "    return s\n",
        "\n",
        "def load_and_prepare(path: Path) -> Tuple[pd.DataFrame, str, str, str]:\n",
        "    \"\"\"\n",
        "    Loads a CSV, cleans headers, and identifies key columns.\n",
        "    Returns the DataFrame and the identified column names.\n",
        "    \"\"\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df = normalize_headers(df)\n",
        "\n",
        "    stock_col = find_column(df, [\"vehiclestocknumber\", \"stock_number\", \"stock\"])\n",
        "    manager_col = find_column(df, POSSIBLE_MANAGER_COLS)\n",
        "    bd_col = find_column(df, POSSIBLE_BD_COLS)\n",
        "\n",
        "    if stock_col is None:\n",
        "        raise KeyError(f\"Could not find a stock number column in file: {path}\")\n",
        "\n",
        "    # If missing, create empty columns to keep logic simple\n",
        "    if manager_col is None:\n",
        "        manager_col = \"__manager_missing__\"\n",
        "        df[manager_col] = \"\"\n",
        "    if bd_col is None:\n",
        "        bd_col = \"__bd_missing__\"\n",
        "        df[bd_col] = \"\"\n",
        "\n",
        "    df[stock_col] = cleaned_series(df[stock_col])\n",
        "    df[manager_col] = cleaned_series(df[manager_col])\n",
        "    df[bd_col] = cleaned_series(df[bd_col])\n",
        "\n",
        "    return df, stock_col, manager_col, bd_col\n",
        "\n",
        "def get_attribution_set(row: Dict[str, Any], manager_col: str, bd_col: str) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extracts and cleans manager/BD agent names from a row into a set.\n",
        "    \"\"\"\n",
        "    names = {row[manager_col], row[bd_col]}\n",
        "    return {name for name in names if name and name not in BAD_SENTINELS}\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        crm_path = Path(CRM_FILE)\n",
        "        dms_path = Path(DMS_FILE)\n",
        "\n",
        "        # Load + prep both files\n",
        "        crm_df, crm_stock, crm_mgr_col, crm_bd_col = load_and_prepare(crm_path)\n",
        "        dms_df, dms_stock, dms_mgr_col, dms_bd_col = load_and_prepare(dms_path)\n",
        "\n",
        "        # Create lookup dictionaries for efficient comparison\n",
        "        crm_dict = crm_df.drop_duplicates(subset=crm_stock).set_index(crm_stock).T.to_dict('dict')\n",
        "        dms_dict = dms_df.drop_duplicates(subset=dms_stock).set_index(dms_stock).T.to_dict('dict')\n",
        "\n",
        "        mismatches = []\n",
        "\n",
        "        target_manager_normalized = TARGET_MANAGER.strip().lower()\n",
        "\n",
        "        # Iterate over all unique stock numbers present in either file\n",
        "        all_stocks = set(crm_dict.keys()).union(set(dms_dict.keys()))\n",
        "\n",
        "        for stock_num in all_stocks:\n",
        "            crm_row = crm_dict.get(stock_num)\n",
        "            dms_row = dms_dict.get(stock_num)\n",
        "\n",
        "            crm_reps = get_attribution_set(crm_row, crm_mgr_col, crm_bd_col) if crm_row else set()\n",
        "            dms_reps = get_attribution_set(dms_row, dms_mgr_col, dms_bd_col) if dms_row else set()\n",
        "\n",
        "            # Check if the target manager is involved in this sale\n",
        "            if target_manager_normalized in crm_reps or target_manager_normalized in dms_reps:\n",
        "                # Check for a mismatch in the combined set of attributed reps\n",
        "                if crm_reps != dms_reps:\n",
        "                    mismatches.append({\n",
        "                        \"stock_number\": stock_num,\n",
        "                        \"crm_attribution\": sorted(list(crm_reps)) if crm_reps else \"unassigned\",\n",
        "                        \"dms_attribution\": sorted(list(dms_reps)) if dms_reps else \"unassigned\",\n",
        "                    })\n",
        "\n",
        "        mismatch_df = pd.DataFrame(mismatches)\n",
        "\n",
        "        print(f\"\\n=== Mismatches for Manager: {TARGET_MANAGER.title()} by Stock Number ===\")\n",
        "        if not mismatch_df.empty:\n",
        "            mismatch_df['crm_attribution'] = mismatch_df['crm_attribution'].apply(lambda x: \", \".join(x).title() if isinstance(x, list) else x.title())\n",
        "            mismatch_df['dms_attribution'] = mismatch_df['dms_attribution'].apply(lambda x: \", \".join(x).title() if isinstance(x, list) else x.title())\n",
        "            print(mismatch_df.to_string(index=False))\n",
        "        else:\n",
        "            print(f\"No discrepancies found for {TARGET_MANAGER.title()} between CRM and DMS attribution.\")\n",
        "        print(\"-----------------------------------------------------\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Please ensure the input files are uploaded and the names match the configuration.\", file=sys.stderr)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: A required column was not found in one of the files: {e}\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKNSR1fzyBCB",
        "outputId": "cf2887fe-1ffe-4f07-8057-082c661721ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Mismatches for Manager: Suna Faitarouny by Stock Number ===\n",
            "stock_number crm_attribution dms_attribution\n",
            "     mp10225      Unassigned Suna Faitarouny\n",
            "     mp10335      Unassigned Suna Faitarouny\n",
            "-----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "repeatable_missing_rows_finder.py\n",
        "\n",
        "Task:\n",
        "- Reads two CSV files specified by the user.\n",
        "- Compares vehicle stock numbers to find records present in the DMS file\n",
        "  but missing from the Google Sheet file.\n",
        "- Outputs the complete missing rows in a format that matches the Google Sheet's\n",
        "  column order, ready for pasting.\n",
        "\n",
        "This script is designed for easy use in Google Colab with minimal changes.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   USER CONFIGURATION SECTION\n",
        "#   Change these two variables to point to your input files.\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# Name of the primary sales file (DMS)\n",
        "DMS_FILE = \"/PaytonListtxt.csv\"\n",
        "\n",
        "# Name of the Google Sheet file you want to update\n",
        "SHEET_FILE = \"/August Google sheet  - Main (10).csv\"\n",
        "\n",
        "# =============================================================================\n",
        "#\n",
        "#   CORE SCRIPT LOGIC (DO NOT CHANGE BELOW THIS LINE)\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "BAD_STOCK_VALUES = {\"\", \"NAN\", \"NONE\", \"NULL\"}\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    \"\"\"Normalizes a column header for consistent access.\"\"\"\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def find_stock_col(cols) -> str | None:\n",
        "    \"\"\"\n",
        "    Tries to find the stock number column from a list of headers.\n",
        "    Returns the normalized column name if found, otherwise None.\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        \"vehiclestocknumber\", \"stock_number\", \"stocknumber\",\n",
        "        \"vehicle_stock_number\", \"stock\", \"stock_no\", \"stocknum\"\n",
        "    ]\n",
        "    normalized_cols = [normalize_header(c) for c in cols]\n",
        "    for c in candidates:\n",
        "        if c in normalized_cols:\n",
        "            return c\n",
        "    for c in normalized_cols:\n",
        "        if \"stock\" in c:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def load_norm(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Loads a CSV and normalizes its headers.\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [normalize_header(c) for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def build_output(dms_df: pd.DataFrame, sheet_df: pd.DataFrame, sheet_path_for_headers: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Builds the output DataFrame of missing rows,\n",
        "    formatted to match the Google Sheet's column order.\n",
        "    \"\"\"\n",
        "    dms_stock = find_stock_col(dms_df.columns)\n",
        "    sheet_stock = find_stock_col(sheet_df.columns)\n",
        "\n",
        "    if dms_stock is None or sheet_stock is None:\n",
        "        print(\"Error: Could not find a stock number column in one or both files. Returning empty DataFrame.\", file=sys.stderr)\n",
        "        sheet_headers_original = list(pd.read_csv(sheet_path_for_headers, nrows=0).columns)\n",
        "        return pd.DataFrame(columns=sheet_headers_original)\n",
        "\n",
        "    dms_df[\"__stock__\"] = dms_df[dms_stock].astype(str).str.upper().str.strip()\n",
        "    sheet_df[\"__stock__\"] = sheet_df[sheet_stock].astype(str).str.upper().str.strip()\n",
        "\n",
        "    dms_df = dms_df[~dms_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "    sheet_df = sheet_df[~sheet_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "\n",
        "    sheet_keys = set(sheet_df[\"__stock__\"])\n",
        "    missing_keys = [s for s in dms_df[\"__stock__\"].tolist() if s not in sheet_keys]\n",
        "    if not missing_keys:\n",
        "        print(\"No missing stock numbers found. Returning empty DataFrame.\", file=sys.stderr)\n",
        "        return pd.DataFrame(columns=pd.read_csv(sheet_path_for_headers, nrows=0).columns)\n",
        "\n",
        "    missing_rows = dms_df[dms_df[\"__stock__\"].isin(missing_keys)].copy()\n",
        "\n",
        "    sheet_headers_original = list(pd.read_csv(sheet_path_for_headers, nrows=0).columns)\n",
        "    sheet_headers_norm = [normalize_header(c) for c in sheet_headers_original]\n",
        "    norm_to_orig = {n: o for n, o in zip(sheet_headers_norm, sheet_headers_original)}\n",
        "\n",
        "    out = pd.DataFrame(columns=sheet_headers_original)\n",
        "    for norm_col in sheet_headers_norm:\n",
        "        orig_col = norm_to_orig[norm_col]\n",
        "        # Check for specific columns and map them from the DMS file\n",
        "        if norm_col == \"sale_date\":\n",
        "            # Explicitly map 'sale_date' from DMS to the output 'Sale Date' column\n",
        "            if \"sale_date\" in missing_rows.columns:\n",
        "                out[orig_col] = missing_rows[\"sale_date\"]\n",
        "        elif norm_col == \"f_&_i\":\n",
        "            if \"f_&_i\" in missing_rows.columns:\n",
        "                out[orig_col] = missing_rows[\"f_&_i\"]\n",
        "            elif \"f_&_i_1\" in missing_rows.columns:\n",
        "                out[orig_col] = missing_rows[\"f_&_i_1\"]\n",
        "        elif norm_col == \"f_&_i_2\":\n",
        "            if \"f_&_i_2\" in missing_rows.columns:\n",
        "                out[orig_col] = missing_rows[\"f_&_i_2\"]\n",
        "        elif norm_col in missing_rows.columns:\n",
        "            out[orig_col] = missing_rows[norm_col]\n",
        "        elif norm_col == \"vehiclestocknumber\":\n",
        "            out[orig_col] = missing_rows[dms_stock].astype(str).str.upper().str.strip()\n",
        "        else:\n",
        "            out[orig_col] = \"\"\n",
        "\n",
        "    out[\"__order__\"] = missing_rows.index\n",
        "    out = out.sort_values(\"__order__\", kind=\"stable\").drop(columns=\"__order__\")\n",
        "\n",
        "    return out\n",
        "\n",
        "def to_csv_markdown(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Converts a DataFrame to a CSV string without index.\"\"\"\n",
        "    return df.to_csv(index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        dms_df = load_norm(Path(DMS_FILE))\n",
        "        sheet_df = load_norm(Path(SHEET_FILE))\n",
        "\n",
        "        output_df = build_output(dms_df, sheet_df, Path(SHEET_FILE))\n",
        "\n",
        "        print(\"\\n\" + to_csv_markdown(output_df))\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Please ensure both files are uploaded to your Colab session and the names match exactly.\", file=sys.stderr)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZCFLWroqoa",
        "outputId": "b9c3a74d-8c15-4e21-cf6a-e562af037c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column 1,salesrepname,splitsalesrep,Manager,BD Agent,F & I,F & I 2,vehiclestocknumber,First Name,Last Name,lead_source,Notes,Column 2\n",
            ",Tony Durazo,,Suna Faitarouny,,Brent Beck,,MP10319,Michelle,Gill,CARFAX,,\n",
            ",Youcef Bacha,,,,Brent Beck,,MP9898A,Nicholas,Jordan,CARGURUS,,\n",
            ",,,,,,,MP9902A,,,,,\n",
            ",Will Deguire,Robert Emmons,Levi Polege,,Mark Rector,,MP8991,John,Schwieterman,AUTOTRADER,,\n",
            ",Kevin Claypool,,Suna Faitarouny,,Mark Rector,,MP8793A,Natasha,Juan,CARGURUS,,\n",
            ",Jordan Lecky,,Suna Faitarouny,,Mark Rector,,MP9794,Hugh,Thompson,AUTOTRADER,,\n",
            ",Tony Durazo,,Suna Faitarouny,,Yesenia Felix,,MP10063,Dede,Moore,DEALERS WEBSITE,,\n",
            ",Robert Emmons,,Suna Faitarouny,,Mark Rector,,MP10065,Braden,Peters,,,\n",
            ",Jordan Lecky,,Suna Faitarouny,,Yesenia Felix,,MP10074,O'Neil,Hersman,CARGURUS,,\n",
            ",Youcef Bacha,Tony Durazo,Suna Faitarouny,,Yesenia Felix,,MP10121,Mark,Shilton,,,\n",
            ",Brandon Beltran,Tony Durazo,Jamie Sheridan,,Mark Rector,,MP10217,Teresa,Blackhair,\"CARS.COM\r\",,\n",
            ",,,,,,,MP9826A,Brandon,Dunlap,,,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "repeatable_missing_rows_finder.py\n",
        "\n",
        "Output schema (exact order):\n",
        "sale_date, salesrepname, splitsalesrep, manager, bd_agent,\n",
        "f_&_i, f_&_i_2, vehiclestocknumber, first_name, last_name, lead_source\n",
        "\"\"\"\n",
        "\n",
        "import sys, csv\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Iterable, Optional\n",
        "\n",
        "# ===================== USER CONFIG =====================\n",
        "DMS_FILE = \"/PaytonListtxt.csv\"                  # e.g., DeskManager / DMS export\n",
        "SHEET_FILE = \"/content/August Google sheet  - Main.csv\"  # your Google Sheet export\n",
        "# ======================================================\n",
        "\n",
        "BAD_STOCK_VALUES = {\"\", \"NAN\", \"NONE\", \"NULL\"}\n",
        "\n",
        "OUTPUT_COLUMNS = [\n",
        "    \"sale_date\", \"salesrepname\", \"splitsalesrep\", \"manager\", \"bd_agent\",\n",
        "    \"f_&_i\", \"f_&_i_2\", \"vehiclestocknumber\", \"first_name\", \"last_name\", \"lead_source\"\n",
        "]\n",
        "\n",
        "COLUMN_VARIANTS = {\n",
        "    \"sale_date\":        [\"sale_date\", \"sale date\", \"date\", \"date_of_sale\", \"sold_date\"],\n",
        "    \"salesrepname\":     [\"salesrepname\", \"sales_rep_name\", \"sales_rep\", \"rep\", \"salesperson\"],\n",
        "    \"splitsalesrep\":    [\"splitsalesrep\", \"split_sales_rep\", \"splitrep\", \"split_salesperson\"],\n",
        "    \"manager\":          [\"manager\", \"sales_manager\", \"desk_manager\"],\n",
        "    \"bd_agent\":         [\"bd_agent\", \"bdagent\", \"bd\", \"bd_agent_name\", \"bd rep\"],\n",
        "    \"f_&_i\":            [\"f_&_i\", \"f & i\", \"f_i\", \"finance_manager\", \"fni\", \"f and i\"],\n",
        "    \"f_&_i_2\":          [\"f_&_i_2\", \"f & i 2\", \"f_i_2\", \"finance_manager_2\", \"fni_2\", \"f and i 2\"],\n",
        "    \"vehiclestocknumber\": [\"vehiclestocknumber\", \"vehicle_stock_number\", \"stock_number\", \"stocknumber\", \"stock\", \"stock_no\", \"stocknum\"],\n",
        "    \"first_name\":       [\"first_name\", \"first name\", \"fname\", \"customer_first_name\"],\n",
        "    \"last_name\":        [\"last_name\", \"last name\", \"lname\", \"customer_last_name\", \"surname\"],\n",
        "    \"lead_source\":      [\"lead_source\", \"lead source\", \"source\", \"leadsource\"]\n",
        "}\n",
        "\n",
        "def normalize_header(col: str) -> str:\n",
        "    return str(col).strip().lower().replace(\" \", \"_\").replace(\"#\", \"number\")\n",
        "\n",
        "def load_norm(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [normalize_header(c) for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def find_first(df: pd.DataFrame, candidates: Iterable[str]) -> Optional[str]:\n",
        "    normalized = [normalize_header(c) for c in candidates]\n",
        "    df_cols = set(df.columns)\n",
        "    for c in normalized:\n",
        "        if c in df_cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def find_stock_col(cols) -> Optional[str]:\n",
        "    candidates = [\n",
        "        \"vehiclestocknumber\", \"stock_number\", \"stocknumber\",\n",
        "        \"vehicle_stock_number\", \"stock\", \"stock_no\", \"stocknum\"\n",
        "    ]\n",
        "    normalized_cols = [normalize_header(c) for c in cols]\n",
        "    for c in candidates:\n",
        "        if c in normalized_cols:\n",
        "            return c\n",
        "    for c in normalized_cols:\n",
        "        if \"stock\" in c:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def clean_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Blank out NaNs/'nan', trim whitespace, normalize newlines, drop quote-only rows.\"\"\"\n",
        "    df = df.copy().where(df.notna(), \"\")\n",
        "    for c in df.columns:\n",
        "        df[c] = (\n",
        "            df[c].astype(str)\n",
        "                 .str.replace(r\"^\\s*nan\\s*$\", \"\", regex=True)\n",
        "                 .str.replace(\"\\r\\n\", \"\\n\")\n",
        "                 .str.replace(\"\\r\", \"\\n\")\n",
        "                 .str.strip()\n",
        "        )\n",
        "    # drop rows that collapse to just a single double-quote\n",
        "    mask_bad = df.apply(lambda r: \"\".join(r.values.astype(str)).strip() == '\"', axis=1)\n",
        "    return df[~mask_bad]\n",
        "\n",
        "def build_output(dms_df: pd.DataFrame, sheet_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    dms_stock = find_stock_col(dms_df.columns)\n",
        "    sheet_stock = find_stock_col(sheet_df.columns)\n",
        "    if dms_stock is None or sheet_stock is None:\n",
        "        raise ValueError(\"Could not find a stock number column in one or both files.\")\n",
        "\n",
        "    dms_df[\"__stock__\"] = dms_df[dms_stock].astype(str).str.upper().str.strip()\n",
        "    sheet_df[\"__stock__\"] = sheet_df[sheet_stock].astype(str).str.upper().str.strip()\n",
        "\n",
        "    dms_df = dms_df[~dms_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "    sheet_df = sheet_df[~sheet_df[\"__stock__\"].isin(BAD_STOCK_VALUES)]\n",
        "\n",
        "    sheet_keys = set(sheet_df[\"__stock__\"])\n",
        "    missing_keys = [s for s in dms_df[\"__stock__\"].tolist() if s not in sheet_keys]\n",
        "    if not missing_keys:\n",
        "        return pd.DataFrame(columns=OUTPUT_COLUMNS)\n",
        "\n",
        "    missing_rows = dms_df[dms_df[\"__stock__\"].isin(missing_keys)].copy()\n",
        "    missing_rows[\"__order__\"] = range(len(missing_rows))\n",
        "\n",
        "    out = pd.DataFrame(index=missing_rows.index, columns=OUTPUT_COLUMNS, dtype=object)\n",
        "    for out_col in OUTPUT_COLUMNS:\n",
        "        if out_col == \"vehiclestocknumber\":\n",
        "            out[out_col] = missing_rows[\"__stock__\"]\n",
        "            continue\n",
        "        src_col = find_first(missing_rows, COLUMN_VARIANTS[out_col])\n",
        "        out[out_col] = missing_rows[src_col] if src_col else \"\"\n",
        "\n",
        "    out[\"__order__\"] = missing_rows[\"__order__\"]\n",
        "    out = out.sort_values(\"__order__\", kind=\"stable\").drop(columns=\"__order__\")\n",
        "\n",
        "    # force strings\n",
        "    for c in OUTPUT_COLUMNS:\n",
        "        out[c] = out[c].astype(str)\n",
        "\n",
        "    return clean_strings(out)\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        dms_df = load_norm(Path(DMS_FILE))\n",
        "        sheet_df = load_norm(Path(SHEET_FILE))\n",
        "        output_df = build_output(dms_df, sheet_df)\n",
        "\n",
        "        # Paste-friendly TSV (optional file)\n",
        "        output_df.to_csv(\"missing_rows.tsv\", sep=\"\\t\", index=False, lineterminator=\"\\n\")\n",
        "\n",
        "        # Clean CSV (fully quoted for Import)\n",
        "        output_df.to_csv(\n",
        "            \"missing_rows.csv\",\n",
        "            index=False,\n",
        "            lineterminator=\"\\n\",\n",
        "            quoting=csv.QUOTE_ALL,\n",
        "            escapechar=\"\\\\\",\n",
        "            na_rep=\"\"\n",
        "        )\n",
        "\n",
        "        # Console preview (CSV, normal-looking)\n",
        "        print(output_df.to_csv(index=False, lineterminator=\"\\n\"))\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Make sure both files are uploaded and paths are correct.\", file=sys.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oByHUFr8zPoO",
        "outputId": "dd5c9004-a4e1-4a11-d2d8-05d8a7bb0b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sale_date,salesrepname,splitsalesrep,manager,bd_agent,f_&_i,f_&_i_2,vehiclestocknumber,first_name,last_name,lead_source\n",
            "8/11/25,,,,,,,MP9880A,WILLIAM,DEGUIRE,\n",
            "8/11/25,,,,,,,MP10059A,KURT,JENSEN,\n",
            "8/11/25,,,,,,,MP9181A,KURT,JENSEN,\n",
            "8/13/25,Brandon Beltran,Tony Durazo,Jamie Sheridan,,Mark Rector,,MP10217,Teresa,Blackhair,CARS.COM\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}